{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selinpinarkoc/UrbanSoundClassification/blob/main/cnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the required libraries\n",
        "We'll start with importing required libraries.\n",
        "\n",
        "üìå Use the keyword \"import\"."
      ],
      "metadata": {
        "id": "VbtceLj6NY7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import Numpy and Matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from numpy import load"
      ],
      "metadata": {
        "id": "v1Xwg1WTNYYS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR-JSbjVn2xw"
      },
      "source": [
        "## Model Hazƒ±rlanmasƒ± ve Eƒüitimi\n",
        "\n",
        "a. Bir CNN modeli hazƒ±rlayƒ±n.\n",
        "\n",
        "\n",
        "\n",
        "üìå Use tf.keras.Sequential() to create a model object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQDlKXrc8itW"
      },
      "outputs": [],
      "source": [
        "# Create a model object\n",
        "model = tf.keras.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or7yci-boHrI"
      },
      "source": [
        "### Feature extraction layers\n",
        "\n",
        "\n",
        "For the first two layers, we add a convolution and max pooling layer.\n",
        "\n",
        "üìå Use tf.keras.layers.Conv2D() and tf.keras.layers.MaxPooling2D() to create the layers.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "earLK3oyHchY"
      },
      "outputs": [],
      "source": [
        "# Add a convolution and max pooling layer\n",
        "model.add(tf.keras.layers.Conv2D(32,\n",
        "                                 kernel_size=(3,3),\n",
        "                                 strides=(1,1),\n",
        "                                 padding=\"same\",\n",
        "                                 activation=\"relu\",\n",
        "                                 input_shape=(100,100,1)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-No8HYtqIES"
      },
      "source": [
        "Then, we add more layers. One convolution, one max pooling, and one convolution layer again.\n",
        "\n",
        "üìå Use tf.keras.layers.Conv2D() and tf.keras.layers.MaxPooling2D() to create the layers.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28YwVXCPI_-U"
      },
      "outputs": [],
      "source": [
        "# Add more convolution and max pooling layers\n",
        "model.add(tf.keras.layers.Conv2D(64,\n",
        "                                 kernel_size=(3,3),\n",
        "                                 strides=(1,1),\n",
        "                                 padding=\"same\",\n",
        "                                 activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "model.add(tf.keras.layers.Conv2D(64,\n",
        "                                 kernel_size=(3,3),\n",
        "                                 strides=(1,1),\n",
        "                                 padding=\"same\",\n",
        "                                 activation=\"relu\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEakflSotCXp"
      },
      "source": [
        "### Flatten\n",
        "\n",
        "To connect the 2D convolution and 1D dense layers, we have to \"flatten\" the convolution layer.\n",
        "\n",
        "üìå Use tf.keras.layers.Flatten() to flatten the layers.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFOcj-N9JDuA"
      },
      "outputs": [],
      "source": [
        "# Flatten the convolution layer\n",
        "model.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d_LWo61tdOn"
      },
      "source": [
        "### Classification layers\n",
        "\n",
        "Now that we have the features extracted, we can move on to the classification part. We add two dense layers each with 64 nodes, 0.5 dropout and ReLU activation functions.\n",
        "\n",
        "üìå Use tf.keras.layers.Dense() to create the layers.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t2_5LI5QXso"
      },
      "outputs": [],
      "source": [
        "# Add the dense layer and dropout layer\n",
        "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0,5))\n",
        "# Add the dense layer and dropout layer\n",
        "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0,5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we add two dense layers. Each with 64 nodes, ReLU activations and 0.5 dropouts. Don‚Äôt forget that these are arbitrary numbers that can be adjusted later on to improve the performance. "
      ],
      "metadata": {
        "id": "2YVit7hpxnIa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ebqf6csu5dk"
      },
      "source": [
        "### Output layer\n",
        "\n",
        "As the last part of our neural network, we add the output layer. The number of nodes will be equal to the number of target classes which is 10 in our case. We'll use the softmax activation function in the output layer.\n",
        "\n",
        "üìå Use tf.keras.layers.Dense() to create the layer.\n",
        "\n",
        "üìå Use .add() method of the object to add the layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKLY8LexKtsx"
      },
      "outputs": [],
      "source": [
        "# Add the output layer\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It‚Äôs time for the output layer. Since we have 10 classes we add 10 nodes and use the Softmax activation function. Remember that for multiclass classification problems, we use Softmax at the output layer. "
      ],
      "metadata": {
        "id": "s63GWhewxwsC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK7ZgiBxvUKl"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "Now we have the structure of our model. To configure the model for training, we'll use the .compile() method. Inside the compile method, we have to define the following:\n",
        "*   \"Adam\" for optimizer\n",
        "*   \"Sparse Categorical Crossentropy\" for the loss function\n",
        "\n",
        "\n",
        "üìå Construct the model with the .compile() method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUaqYlMwh566"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we compile the model. We define the optimizer ‚ÄúAdam‚Äù, our go-to optimizer, and since we are trying to solve a multiclass classification problem we use the ‚ÄúSparse Categorical Cross Entropy‚Äù loss function. With this, our model is ready to be trained!"
      ],
      "metadata": {
        "id": "sNhLKSBXxz6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZg_kaL96S8q",
        "outputId": "40938ad4-6d06-4ea9-8792-d824318024dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.load('/content/drive/MyDrive/data/X_train.npy')\n",
        "X_test = np.load('/content/drive/MyDrive/data/X_test.npy')\n",
        "X_val = np.load('/content/drive/MyDrive/data/X_val.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/data/y_train.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/data/y_test.npy')\n",
        "y_val = np.load('/content/drive/MyDrive/data/y_val.npy')"
      ],
      "metadata": {
        "id": "W9Y6mfV69kTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZy3mKryvaGo"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "\n",
        "b. Modeli hazƒ±rlamƒ±≈ü olduƒüunuz veriyi kullanarak eƒüitin.\n",
        "\n",
        "It's time to train the model. We'll give the X_train and y_train datasets as the first two arguments. These will be used for training. And with the *validation_data* parameter, we'll give the X_val and y_val as a tuple.\n",
        "\n",
        "üìå Use .fit() method of the model object for the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGk1WRxhIr3D"
      },
      "outputs": [],
      "source": [
        "# Train the model for 50 epochs with batch size of 128\n",
        "results = model.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=30,\n",
        "                    validation_data=(X_val,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ia8j13SvhWO"
      },
      "source": [
        "### Visualize the results\n",
        "\n",
        "After the model is trained, we can create a graph to visualize the change of loss over time. Results are held in:\n",
        "* results.history[\"loss\"]\n",
        "* results.history[\"val_loss\"]\n",
        "\n",
        "üìå Use plt.show() to display the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCkhCF2mrDuA"
      },
      "outputs": [],
      "source": [
        "# Plot the the training loss\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "\n",
        "# Plot the the validation loss\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxREfAxswVrc"
      },
      "source": [
        "Now do the same thing for accuracy.\n",
        "\n",
        "üìå Accuracy scores can be found in:\n",
        "* results.history[\"accuracy\"]\n",
        "* results.history[\"val_accuracy\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqRG74X-MhyR"
      },
      "outputs": [],
      "source": [
        "# Plot the the training accuracy\n",
        "plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n",
        "\n",
        "# Plot the the validation accuracy\n",
        "plt.plot(results.history[\"val_accuracy\"], label=\"accuracy\")\n",
        "\n",
        "# Name the x and y axises\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Put legend table\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42kVCT4Kw2s8"
      },
      "source": [
        "## Performance evaluation\n",
        "\n",
        "Let's use the test dataset we created to evaluate the performance of the model.\n",
        "\n",
        "üìå Use test_on_batch() method with test dataset as parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhO6jK8AMhiN"
      },
      "outputs": [],
      "source": [
        "# Evaluate the performance\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwfUIHc2w7n1"
      },
      "source": [
        "### Try a prediction\n",
        "\n",
        "Next, we take the sample we selected at the beginning and make a prediction on it.\n",
        "\n",
        "üìå Reshape the image to (1,32,32,3)\n",
        "\n",
        "üìå Use the *.prediction()* method of the model object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tW1rz5wrcFW"
      },
      "outputs": [],
      "source": [
        "# Make prediction on the reshaped sample\n",
        "prediction_result = model.predict(X_test[789.reshape(1,32,32,3)])\n",
        "\n",
        "# Print the prediction result\n",
        "prediction_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIcUKgOK2ysK"
      },
      "source": [
        "Finally, we find the predicted class and prediction probability and print the results.\n",
        "\n",
        "üìå Use .argmax() to find the class.\n",
        "\n",
        "üìå Use .max() to find the probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwzciFW3rq8i"
      },
      "outputs": [],
      "source": [
        "# Find the predicted class\n",
        "predicted_class = prediction_result.argmax()\n",
        "# Find the prediction probability\n",
        "predicted_probability = prediction_result.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the highest probability we can use argmax and max methods. argmax returns the index of the highest value, which is the predicted class, and max returns the probability. Let‚Äôs find these and assign them to variables.\n",
        "\n",
        "Let‚Äôs print the prediction. "
      ],
      "metadata": {
        "id": "dOfgF23O0Yey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y00kvma6aFOn"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(f\"This image belongs to class {predicted_class} with {predicted_probability} probability %\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}